# ğŸ¥ Medibot â€” Retrieval-Augmented Medical Question Answering System

Medibot is a retrieval-augmented medical question-answering system that combines semantic search with controlled language model generation to produce answers grounded in real medical sources.

Unlike generic chatbots, Medibot **retrieves first and generates second** â€” every response is traceable to a specific page in the source encyclopedia, not fabricated from memorized patterns.

---

## ğŸ“¸ Screenshots

<div align="center">
  <img src="assets/images/welcome_screen.jpeg" width="900" alt="Welcome Screen" />
  <br/><br/>
  <img src="assets/images/chat_response.jpeg" width="900" alt="Medical Q&A with citations" />
  <br/><br/>
  <img src="assets/images/source_citations.jpeg" width="900" alt="Source attribution" />
</div>

---

## ğŸ¯ Why Medibot Exists

Large language models are powerful â€” but dangerous in healthcare when they hallucinate. Medibot was built to explore how **Retrieval-Augmented Generation (RAG)** can solve this:

- **Reduce hallucinations** by forcing the model to read before it answers
- **Ground every response** in verifiable, cited medical text
- **Say "I don't know"** when information is genuinely missing
- **Build trust** through source transparency

This is an educational and research project. It demonstrates the same architectural principles used in production medical AI systems â€” at a scale that's clear, learnable, and reproducible.

---

## ğŸ§  What Medibot Does

| Capability | How |
|---|---|
| Answers medical questions | Via a conversational web interface |
| Retrieves relevant passages | Semantic search over 3,400 indexed chunks |
| Grounds responses | LLM prompt is constrained to retrieved context only |
| Cites sources | Every answer includes document name and page numbers |
| Declines gracefully | Returns a safe fallback when data is missing |
| Runs fully local | No API keys â€” models execute on your machine |
| Auto-detects hardware | Uses Apple Silicon MPS, NVIDIA CUDA, or CPU automatically |

---

## ğŸ“š Knowledge Base

| Property | Value |
|---|---|
| **Source** | Gale Encyclopedia of Medicine, 2nd Edition |
| **Volume** | Volume 1 |
| **Topic Coverage** | Aâ€“B only |
| **Pages** | ~700 |
| **Indexed Chunks** | ~3,400 |
| **Vector Index** | FAISS (dense vector similarity search) |
| **Embedding Dimension** | 384 |

> âš ï¸ **Scope Limitation:** The corpus covers **limited topics only**. When a question falls outside this range, Medibot responds:
> *"I am not certain based on the provided medical sources."*
>
> This behavior is intentional â€” not a bug.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      USER QUESTION                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   CHAINLIT WEB UI                        â”‚
â”‚              (conversational interface)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FAISS VECTOR SEARCH                         |
â”‚        semantic similarity over 3,400 chunks             â”‚
â”‚              retrieves top-k = 3                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             CONTEXT ASSEMBLY                             â”‚
â”‚     retrieved chunks â†’ structured prompt                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           FLAN-T5 LLM GENERATION                         â”‚
â”‚     generates answer using ONLY retrieved context        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FINAL RESPONSE                              â”‚
â”‚         answer + source citations + disclaimer           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Design Principles

| Principle | How It's Enforced |
|---|---|
| **Retrieval first** | Vector search executes before any generation step |
| **No hallucination** | Prompt explicitly restricts the model to retrieved context |
| **Source transparency** | Page numbers and document names shown with every answer |
| **Corpus awareness** | System detects and communicates when data is missing |

---

## ğŸ› ï¸ Tech Stack

### Models

| Model | Role | Size |
|---|---|---|
| `sentence-transformers/all-MiniLM-L6-v2` | Converts text into 384-dimensional vectors | ~80 MB |
| `google/flan-t5-base` | Generates answers from retrieved context | ~900 MB |

### Libraries

| Library | Role |
|---|---|
| **LangChain** | Orchestrates the full RAG pipeline (retriever â†’ prompt â†’ LLM) |
| **FAISS** | Stores and searches 3,400 text embeddings at runtime |
| **Sentence-Transformers** | Runs the embedding model |
| **Hugging Face Transformers** | Runs Flan-T5 locally |
| **Chainlit** | Provides the interactive chat UI |
| **PyPDF** | Extracts text from the encyclopedia PDF |
| **PyTorch** | Model inference with hardware acceleration |

### Hardware Support

| Device | Supported | How |
|---|---|---|
| **Apple Silicon (M1/M2/M3)** | âœ… | PyTorch MPS â€” auto-detected at startup |
| **NVIDIA GPU** | âœ… | PyTorch CUDA â€” auto-detected at startup |
| **CPU** | âœ… | Fallback â€” works on any machine |

> Everything runs locally. No external APIs or paid services required. Device selection is automatic â€” `config.py` detects MPS, CUDA, or CPU at import time.

---

## ğŸ“‚ Project Structure

```
MEDIBOT-Medical-RAG-Chatbot/
â”œâ”€â”€ main.py                         # Chainlit app entry point
â”œâ”€â”€ README.md                        # Project overview + setup
â”œâ”€â”€ LICENSE                          # MIT License
â”œâ”€â”€ .gitignore                       # Excludes data, vectorstore, logs, caches
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ chainlit.md                      # Chainlit welcome screen content
â”‚
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ images/                      # Curated screenshots used in README
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # Place encyclopedia PDF here (not committed)
â”‚   â”‚   â””â”€â”€ .gitkeep
â”‚   â””â”€â”€ processed/                   # Reserved for future preprocessing output
â”‚       â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_vectorstore.py          # PDF â†’ chunks â†’ embeddings â†’ FAISS index
â”‚   â”œâ”€â”€ test_rag_quick.py             # Quick end-to-end RAG validation
â”‚   â”œâ”€â”€ test_full_rag.py              # Full pipeline tests
â”‚   â””â”€â”€ diag_native_crash.py          # macOS / native dependency diagnostic
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â””â”€â”€ embedding_generator.py    # SentenceTransformer embedding wrapper
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ pdf_processor.py          # PDF loading + page metadata
â”‚   â”‚   â””â”€â”€ text_splitter.py          # Chunking strategy
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â””â”€â”€ vector_store.py           # FAISS index create/load/search
â”‚   â”œâ”€â”€ generation/
â”‚   â”‚   â”œâ”€â”€ llm_handler.py            # Local Flan-T5 generation wrapper
â”‚   â”‚   â””â”€â”€ prompt_templates.py       # QA prompt + citation formatting
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ config.py                 # Central config + validation
â”‚       â””â”€â”€ logger.py                 # Logging + performance timing
â”‚
â””â”€â”€ vectorstore/
    â””â”€â”€ .gitkeep                      # FAISS artifacts generated locally (not committed)
```

---

## â–¶ï¸ Setup & Usage

### 1. Create Environment

```bash
conda create -n medibot python=3.11 -y
conda activate medibot
pip install -r requirements.txt
```

### 2. Add the Medical PDF

Place the Gale Encyclopedia PDF into the raw data folder:

```bash
cp /path/to/gale_encyclopedia_vol1.pdf data/raw/
```

### 3. Build the Vector Store

This is the core preprocessing step. It reads the PDF, chunks the text, embeds every chunk, and saves a searchable FAISS index.

```bash
python scripts/build_vectorstore.py
```

Expected output:

```
Step 1/4: Processing PDF         â†’  ~700 pages loaded
Step 2/4: Splitting into chunks  â†’  ~3,400 chunks created
Step 3/4: Creating vector store  â†’  Embeddings generated
Step 4/4: Saving to disk         â†’  vectorstore/medibot_faiss_index/

âœ… Vector store built successfully
```

### 4. Validate the Pipeline

Before launching the UI, run the end-to-end test to confirm retrieval and generation work together:

```bash
python scripts/test_rag_quick.py
```

If the full pipeline is working, you will see:

```
âœ… RAG TEST SUCCESSFUL
```

### 5. Run the Application

```bash
chainlit run main.py
```

Open in your browser:

```
http://localhost:8000
```

---

## ğŸ’¬ Example Questions

The following example queries illustrate the range of medical questions Medibot can handle, including factual retrieval, multi-step reasoning, and safe uncertainty handling:

| Example Question | What It Demonstrates |
|---|---|
| *What are the symptoms and common causes of asthma?* | Grounded factual retrieval |
| *How is bronchitis typically diagnosed?* | Evidence-based clinical explanation |
| *Explain Addisonâ€™s disease in simple terms.* | Clear medical summarization |
| *How does appendicitis usually progress if left untreated?* | Temporal and causal reasoning |
| *Can shortness of breath indicate conditions other than asthma?* | Comparative reasoning with safety awareness |
| *What are the symptoms of a condition not found in the sources?* | Correct uncertainty handling (â€œI donâ€™t knowâ€ behavior) |

Every response is generated **strictly from retrieved medical sources**, includes **explicit citations**, and follows a **conservative, non-hallucinatory response policy**.

---

## ğŸ§ª Testing

### Quick Validation

```bash
python scripts/test_rag_quick.py
```

Runs one full query end-to-end. Confirms: **load â†’ search â†’ generate â†’ respond**.

### Full Pipeline Test

```bash
python scripts/test_full_rag.py
```

| Stage | What It Verifies |
|---|---|
| 1 | Vector search returns relevant chunks |
| 2 | LLM generates coherent text independently |
| 3 | Manual RAG pipeline works step by step |
| 4 | LangChain RetrievalQA chain works end-to-end |
| 5 | Edge cases and error handling are robust |

### Safety Checks

| Check | Purpose |
|---|---|
| Keyword grounding verification | Confirms answer relates to retrieved text |
| Context-overlap enforcement | Detects when model ignores context |
| Missing-data refusal | Returns safe fallback instead of guessing |
| Source tracking | Page numbers preserved from PDF through to response |

---

## âš ï¸ Limitations

| Limitation | Details |
|---|---|
| **Corpus scope** | Aâ€“B topics only (Volume 1) |
| **No live data** | Static encyclopedia â€” no internet access |
| **Not diagnostic** | Educational use only |
| **Model size** | Flan-T5-base is lightweight; larger models produce better answers |
| **Language** | English only |
| **First query latency** | 10â€“30s on first run (model loading); 2â€“5s after that |

---

## âš•ï¸ Medical Disclaimer

> **Medibot is for educational and research purposes only.**
>
> It does not provide medical advice, diagnosis, or treatment recommendations. It is not a medical professional and cannot replace doctors, clinicians, or healthcare providers.
>
> **Always consult a qualified healthcare professional for any medical decisions.**

---

## ğŸ¯ Why This Project Matters

Medibot demonstrates three principles that define responsible AI in sensitive domains:

**1. Retrieval reduces hallucination.**
By forcing the model to read relevant text before answering, fabricated responses are dramatically reduced. The model doesn't guess â€” it reads, then answers.

**2. Knowing when not to answer is critical.**
A system that confidently gives wrong medical information is worse than one that says "I don't know." Medibot is designed around this principle.

**3. Source transparency builds trust.**
Every answer shows exactly where it came from â€” document name, page number. Users can verify. That's how trust works.

These are the same principles behind production medical AI systems. Medibot applies them at a scale that's clear, reproducible, and learnable.

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

## ğŸ“¬ Contact

| Platform | Link |
|---|---|
| GitHub | [Vidhikdm](https://github.com/Vidhikdm) |
| LinkedIn | [Vidhi Kadam](https://www.linkedin.com/in/vidhikadam/) |
| Email | vidhi.kadam1501@gmail.com |

---

<p align="center">
  <em>
    Built on the belief that trustworthy medical AI starts with grounded knowledge,
    transparent reasoning, and verifiable sources.
  </em>
</p>